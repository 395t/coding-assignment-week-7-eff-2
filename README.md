# coding-template

## Summary

The summary can contain but is not limited to:

- Code structure.

- Commands to reproduce your experiments.

- Write-up of your findings and conclusions.

- Ipython notebooks can be organized in `notebooks`.

We explored the Longformer, Linformer, Bigbird, and Performer architectures on the IMDB, SST2, QNLI, and QQP datasets.

## Reference

We used the following code references from huggingface and other sources to train and use pretrained models:
https://huggingface.co/transformers/v2.5.0/examples.html
https://github.com/huggingface/transformers/blob/v4.6.0-release/examples/pytorch/text-classification/run_glue.py

https://huggingface.co/google/bigbird-roberta-base
https://huggingface.co/allenai/longformer-base-4096
https://pythonrepo.com/repo/lucidrains-performer-pytorch-python-pytorch-utilities
https://pypi.org/project/linformer-pytorch/

## IMDB

## SST2

### Model and Dataset

### Code

### Performance

### Analysis

## QNLI

## QQP
